As well as considering probabilities defined over discrete sets of events, we also wish to consider probabilities with respect to continuous variables. We shall limit ourselves to a relatively informal discussion. If the probability of a real-valued variable x falling in the interval (x, x + $\Delta$x) is given by *p(x)$\Delta$x* for $\Delta$x $\rightarrow$ 0, then *p(x)* is called the [[probability density]] over x. This is illustrated in [[Figure 1.12.png|Figure 1.12]]. The probability that *x* will lie in an interval *(a, b)* is then given by
$$
p(x \in (a,b)) = \int^b_ap(x)dx
\tag{1.24}
$$
Because probabilities are nonnegative, and because the value of *x* must lie somewhere on the real axis, the probability density *p(x)* must satisfy the two conditions
$$
p(x) \geq 0
\tag{1.25}
$$
$$
\int^\infty_\infty p(x)dx = 1
\tag{1.25}
$$
![[Figure 1.12.png]]
[[Figure 1.12.png|Figure 1.12]]

Under a nonlinear change of variable, a probability density transforms differently from a simple function, due to the Jacobian factor. For instance, if we consider a change of variables *x = g(y)*, then a function *f(x)* becomes $\tilde{f}(y) = f(g(y))$. Now consider a probability density $p_x(x)$ that corresponds to a density $p_y(y)$ with respect to the new variable *y*, where the suffices denote the fact that *px(x)* and *py(y)* are different densities. Observations falling in the range (x, x + $\Delta$x) will, for small values of $\Delta$x, be transformed into the range (y, y + $\Delta$y) where $p_x(x)\delta x \approx py(y)\delta y$, and hence
$$
\begin{align}
p_y(y) = p_x(x) |\frac{dx}{dy}| \\
= p_x(g(y)) |g'(y)|
\end{align}
\tag{1.27}
$$
One consequence of this property is that the concept of the maximum of a probability density is dependent on the choice of variable.

The probability that x lies in the interval (−∞, z) is given by the [[cumulative distribution]] function defined by
$$
P(z) = \int^z_{-\infty}p(x)dx
\tag{1.28}
$$
which satisfies *P'(x) = p(x)*, as shown in Figure [[Figure 1.12.png|Figure 1.12]].

If we have several continuous variables $x_1, ..., x_D$, denoted collectively by the vector *x*, then we can define a joint probability density $p(x) = p(x_1, ..., x_D)$ such that the probability of *x* falling in an infinitesimal volume $\Delta$x containing the point x is given by *p(x)*$\Delta$x. This multivariate probability density must satisfy
$$
p(x) \geq 0
\tag{1.29}
$$
$$
\int p(x)dx = 1
\tag{1.30}
$$
in which the integral is taken over the whole of x space. We can also consider joint probability distributions over a combination of discrete and continuous variables.

Note that if x is a discrete variable, then p(x) is sometimes called a [[probability mass function]] because it can be regarded as a set of ‘probability masses’ concentrated at the allowed values of x.

The sum and product rules of probability, as well as Bayes’ theorem, apply equally to the case of probability densities, or to combinations of discrete and continuous variables. For instance, if x and y are two real variables, then the sum and product rules take the form
$$
p(x) = \int p(x,y)dy
\tag{1.31}
$$
$$
p(x,y) = p(y|x)p(x)
\tag{1.32}
$$
A formal justification of the sum and product rules for continuous variables (Feller, 1966) requires a branch of mathematics called [[measure theory]] and lies outside the scope of this book. Its validity can be seen informally, however, by dividing each real variable into intervals of width $\Delta$ and considering the discrete probability distribution over these intervals. Taking the limit $\Delta$ $\rightarrow$ 0 then turns sums into integrals and gives the desired result.
